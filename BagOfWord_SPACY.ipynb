{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, re, string\n",
    "from collections import Counter, OrderedDict\n",
    "import spacy\n",
    "from spacy.symbols import pobj, nsubj, conj, NOUN, ADJ, PROPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./IRP2019-2021.csv')\n",
    "# nlp = spacy.load('en_core_web_md',parse=True,tag=True,entity=True)\n",
    "nlp = spacy.load('en_core_web_lg',parse=True,tag=True,entity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['ResearchFocus','ResearchObjectives','Keywords','OP1','OP1RelevantDisc','OP2','OP2RelevantDisc',\n",
    "          'OP3','OP3RelevantDisc','OP4','OP4RelevantDisc','FROption 1','FROption 2',\n",
    "          'FROption 3','FROption 4','FROption 5']\n",
    "\n",
    "RF_list = []\n",
    "RO_list = []\n",
    "KW_list = []\n",
    "OP_list = []\n",
    "FR_list = []\n",
    "for col in columns:\n",
    "    for ind in df.index:\n",
    "        if pd.notna(df[col][ind]) :\n",
    "            if col == 'ResearchFocus':\n",
    "                RF_list.append(df[col][ind])\n",
    "            elif col == 'ResearchObjectives':\n",
    "                RO_list.append(df[col][ind])\n",
    "            elif col == 'Keywords':\n",
    "                KW_list.append(df[col][ind])\n",
    "            elif col == 'OP1' or col == 'OP1RelevantDisc' or col == 'OP2' or col == 'OP2RelevantDisc' or col == 'OP3' or col == 'OP3RelevantDisc' or col == 'OP4' or col == 'OP4RelevantDisc' :\n",
    "                OP_list.append(df[col][ind])\n",
    "            elif col == 'FROption 1' or 'FROption 2' or 'FROption 3' or 'FROption 4' or 'FROption 5':\n",
    "                FR_list.append(df[col][ind])\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "RF_list = ', '.join(RF_list)\n",
    "RO_list = ', '.join(RO_list)\n",
    "KW_list = ', '.join(KW_list)\n",
    "OP_list = ', '.join(OP_list)\n",
    "FR_list = ', '.join(FR_list)\n",
    "\n",
    "RF_doc = nlp(RF_list)\n",
    "RO_doc = nlp(RO_list)\n",
    "KW_doc = nlp(KW_list)\n",
    "OP_doc = nlp(OP_list)\n",
    "FR_doc = nlp(FR_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for token in RF_doc:\n",
    "#     if token.is_stop == False and token.pos_ != 'PUNCT' and token.pos_ != 'SPACE' and token.pos_ != 'SYM':\n",
    "#         print(token.lemma_,'--',token.dep_,'--',token.head.text,'--',[child for child in token.children],'--',token.pos_,'--',token.shape_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stopwords = ['architecture','Architecture','work','design','Design','research','publication','focus',\n",
    "                 'Pratt','funding','form','student','Osorio']\n",
    "\n",
    "for w in new_stopwords:\n",
    "    nlp.vocab[w].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('technology', 9),\n",
       " ('climate change', 6),\n",
       " ('development', 5),\n",
       " ('the city', 5),\n",
       " ('communities', 4),\n",
       " ('order', 4),\n",
       " ('space', 4),\n",
       " ('economic social', 3),\n",
       " ('african Indigenous', 3),\n",
       " ('management', 3),\n",
       " ('housing', 3),\n",
       " ('material', 3),\n",
       " ('landscape', 3),\n",
       " ('place', 3),\n",
       " ('the intersection', 3),\n",
       " ('planning', 3),\n",
       " ('photography', 3),\n",
       " ('urbanism', 3),\n",
       " ('the history', 3),\n",
       " ('cultural architectural', 2),\n",
       " ('level including', 2),\n",
       " ('justice equity', 2),\n",
       " ('environmental social', 2),\n",
       " ('theory History', 2),\n",
       " ('exhibition schools', 2),\n",
       " ('structures', 2),\n",
       " ('blockchain', 2),\n",
       " ('nature', 2),\n",
       " ('the study', 2),\n",
       " ('designers', 2),\n",
       " ('systems', 2),\n",
       " ('the way', 2),\n",
       " ('the field', 2),\n",
       " ('the virtual', 2),\n",
       " ('play', 2),\n",
       " ('ecology', 2),\n",
       " ('theory', 2),\n",
       " ('scenarios', 2),\n",
       " ('scales', 2),\n",
       " ('technologies', 2),\n",
       " ('the country', 2),\n",
       " ('cities', 2),\n",
       " ('construction', 2),\n",
       " ('color', 2),\n",
       " ('practices', 2),\n",
       " ('intervention', 2),\n",
       " ('the program', 2),\n",
       " ('a discipline', 2),\n",
       " ('study', 2),\n",
       " ('rising sea levels', 2)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_cnt = Counter()\n",
    "for token in RF_doc:\n",
    "    if ((token.pos == NOUN or token.pos == ADJ or token.pos == PROPN) and (token.dep == pobj or token.dep == conj)):\n",
    "#         print(token.lemma_, token.head.text)\n",
    "        if token.head.is_stop == False:\n",
    "            txt = token.lemma_ + ' ' + token.head.text\n",
    "            RF_cnt[txt] += 1\n",
    "\n",
    "for chunk in RF_doc.noun_chunks:\n",
    "    if chunk.root.is_stop == False and (chunk.root.pos == NOUN or chunk.root.pos == ADJ or token.pos == PROPN) and (chunk.root.dep == pobj or chunk.root.dep == conj) :\n",
    "#         print(chunk.text)\n",
    "        RF_cnt[chunk.text] += 1\n",
    "\n",
    "for token in RF_doc:\n",
    "    if (token.dep_ == 'compound' and token.head.is_stop == False):\n",
    "#         print(token.lemma_, token.head.text)\n",
    "        txt = token.lemma_ + ' ' + token.head.text\n",
    "        if not not(nlp(txt).ents):\n",
    "            if nlp(txt).ents[0].label_ != 'GPE':\n",
    "                RF_cnt[txt] += 1\n",
    "        \n",
    "RF_cnt.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('collaboration', 5),\n",
       " ('communities', 5),\n",
       " ('african Indigenous', 4),\n",
       " ('order', 4),\n",
       " ('materials', 4),\n",
       " ('renewable energy', 4),\n",
       " ('housing', 4),\n",
       " ('Pratt Institute', 4),\n",
       " ('engineering', 3),\n",
       " ('modernity', 3),\n",
       " ('climate change', 3),\n",
       " ('the Fall', 3),\n",
       " ('technologies', 3),\n",
       " ('workshops', 3),\n",
       " ('time', 3),\n",
       " ('a book', 3),\n",
       " ('precedents', 3),\n",
       " ('a series', 3),\n",
       " ('engineering science', 2),\n",
       " ('cultural social', 2),\n",
       " ('historical theoretical', 2),\n",
       " ('material engineering', 2),\n",
       " ('practice theories', 2),\n",
       " ('architecture photography', 2),\n",
       " ('machine learning', 2),\n",
       " ('books', 2),\n",
       " ('that end', 2),\n",
       " ('the country', 2),\n",
       " ('art', 2),\n",
       " ('the city', 2),\n",
       " ('automation', 2),\n",
       " ('geometry', 2),\n",
       " ('exhibition', 2),\n",
       " ('the scale', 2),\n",
       " ('construction methods', 2),\n",
       " ('development', 2),\n",
       " ('aesthetics', 2),\n",
       " ('beauty', 2),\n",
       " ('designers', 2),\n",
       " ('the built environment', 2),\n",
       " ('a set', 2),\n",
       " ('articles', 2),\n",
       " ('Egyptâ€™s modern history', 2),\n",
       " ('modernization', 2),\n",
       " ('construction', 2),\n",
       " ('the studio', 2),\n",
       " ('the program', 2),\n",
       " ('native pollinators', 2),\n",
       " ('applications', 2),\n",
       " ('environments', 2)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RO_cnt = Counter()\n",
    "for token in RO_doc:\n",
    "    if ((token.pos == NOUN or token.pos == ADJ or token.pos == PROPN) and (token.dep == pobj or token.dep == conj)):\n",
    "#         print(token.lemma_, token.head.text)\n",
    "        if token.head.is_stop == False:\n",
    "            txt = token.lemma_ + ' ' + token.head.text\n",
    "            RO_cnt[txt] += 1\n",
    "\n",
    "for chunk in RO_doc.noun_chunks:\n",
    "    if chunk.root.is_stop == False and (chunk.root.pos == NOUN or chunk.root.pos == ADJ or token.pos == PROPN) and (chunk.root.dep == pobj or chunk.root.dep == conj) :\n",
    "#         print(chunk.text)\n",
    "        RO_cnt[chunk.text] += 1\n",
    "\n",
    "for token in RO_doc:\n",
    "    if (token.dep_ == 'compound' and token.head.is_stop == False):\n",
    "#         print(token.lemma_, token.head.text)\n",
    "        txt = token.lemma_ + ' ' + token.head.text\n",
    "        if not not(nlp(txt).ents):\n",
    "            if nlp(txt).ents[0].label_ != 'GPE':\n",
    "                RO_cnt[txt] += 1\n",
    "        \n",
    "RO_cnt.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('history', 3),\n",
       " ('housing', 3),\n",
       " ('urban agriculture', 3),\n",
       " ('machine learning', 3),\n",
       " ('sustainability', 3),\n",
       " ('climate change', 3),\n",
       " ('housing housing', 2),\n",
       " ('heritage interpretation', 2),\n",
       " ('design planning', 2),\n",
       " ('drawing drawing', 2),\n",
       " ('robotics', 2),\n",
       " ('ecology', 2),\n",
       " ('material', 2),\n",
       " ('systems', 2),\n",
       " ('environment', 2),\n",
       " ('affordable housing', 2),\n",
       " ('urban planning', 2),\n",
       " ('green infrastructure', 2),\n",
       " ('soil', 2),\n",
       " ('deep section', 2),\n",
       " ('3d printing', 2),\n",
       " ('food', 2),\n",
       " ('materials', 2),\n",
       " ('carbon', 2),\n",
       " ('Climate Change', 2),\n",
       " ('Architectural history', 2),\n",
       " ('representation', 2),\n",
       " ('modernity', 2),\n",
       " ('media', 2),\n",
       " ('development', 2),\n",
       " ('Visual Thinking', 2),\n",
       " ('environmental justice', 2),\n",
       " ('cities', 2),\n",
       " ('urbanism', 2),\n",
       " ('Automation Fabrication', 1),\n",
       " ('Software Automation', 1),\n",
       " ('Manufacturing Software', 1),\n",
       " ('Design Manufacturing', 1),\n",
       " ('Symbolism Culture', 1),\n",
       " ('structure Symbolism', 1),\n",
       " ('Technology Consciousness', 1),\n",
       " ('Genomics Technology', 1),\n",
       " ('creativity Genomics', 1),\n",
       " ('technology Creativity', 1),\n",
       " ('technology technology', 1),\n",
       " ('learning technology', 1),\n",
       " ('robotic learning', 1),\n",
       " ('AI robotics', 1),\n",
       " ('system Structures', 1),\n",
       " ('chain systems', 1)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KW_cnt = Counter()\n",
    "for token in KW_doc:\n",
    "    if ((token.pos == NOUN or token.pos == ADJ or token.pos == PROPN) and (token.dep == pobj or token.dep == conj)):\n",
    "#         print(token.lemma_, token.head.text)\n",
    "        if token.head.is_stop == False:\n",
    "            txt = token.lemma_ + ' ' + token.head.text\n",
    "            KW_cnt[txt] += 1\n",
    "\n",
    "for chunk in KW_doc.noun_chunks:\n",
    "    if chunk.root.is_stop == False and (chunk.root.pos == NOUN or chunk.root.pos == ADJ or token.pos == PROPN) and (chunk.root.dep == pobj or chunk.root.dep == conj) :\n",
    "#         print(chunk.text)\n",
    "        KW_cnt[chunk.text] += 1\n",
    "\n",
    "for token in KW_doc:\n",
    "    if (token.dep_ == 'compound' and token.head.is_stop == False):\n",
    "#         print(token.lemma_, token.head.text)\n",
    "        txt = token.lemma_ + ' ' + token.head.text\n",
    "        if not not(nlp(txt).ents):\n",
    "            if nlp(txt).ents[0].label_ != 'GPE':\n",
    "                KW_cnt[txt] += 1\n",
    "        \n",
    "KW_cnt.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pratt Institute', 21),\n",
       " ('J. C.', 16),\n",
       " ('Planning', 15),\n",
       " ('the city', 13),\n",
       " ('landscape', 11),\n",
       " ('students', 11),\n",
       " ('the project', 9),\n",
       " ('Urban Planning', 9),\n",
       " ('planning', 8),\n",
       " ('collaboration', 8),\n",
       " ('Rome', 8),\n",
       " ('water', 8),\n",
       " ('my teaching', 7),\n",
       " ('teaching', 7),\n",
       " ('development', 6),\n",
       " ('NYC', 6),\n",
       " ('the public', 6),\n",
       " ('the studio', 6),\n",
       " ('GIS', 6),\n",
       " ('China', 6),\n",
       " ('Sunset Park', 6),\n",
       " ('climate change', 6),\n",
       " ('Visualization Initiative', 6),\n",
       " ('Digital Arts', 6),\n",
       " ('Photography', 6),\n",
       " ('Mechanical Engineering', 6),\n",
       " ('Urbanism', 6),\n",
       " ('E.', 6),\n",
       " ('Sustainable Systems', 6),\n",
       " ('history history', 5),\n",
       " ('Representation', 5),\n",
       " ('urban planning', 5),\n",
       " ('my students', 5),\n",
       " ('the history', 5),\n",
       " ('Yale', 5),\n",
       " ('this topic', 5),\n",
       " ('New York', 5),\n",
       " ('Robotics', 5),\n",
       " ('History', 5),\n",
       " ('architectural history', 5),\n",
       " ('Art', 5),\n",
       " ('Columbia University', 5),\n",
       " ('Fluid Frontiers', 5),\n",
       " ('seminar studios', 4),\n",
       " ('Yale RISD', 4),\n",
       " ('planning landscape', 4),\n",
       " ('Mimi Lobell', 4),\n",
       " ('addition', 4),\n",
       " ('the University', 4),\n",
       " ('Hong Kong', 4)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OP_cnt = Counter()\n",
    "for token in OP_doc:\n",
    "    if ((token.pos == NOUN or token.pos == ADJ or token.pos == PROPN) and (token.dep == pobj or token.dep == conj)):\n",
    "#         print(token.lemma_, token.head.text)\n",
    "        if token.head.is_stop == False:\n",
    "            txt = token.lemma_ + ' ' + token.head.text\n",
    "            OP_cnt[txt] += 1\n",
    "\n",
    "for chunk in OP_doc.noun_chunks:\n",
    "    if chunk.root.is_stop == False and (chunk.root.pos == NOUN or chunk.root.pos == ADJ or token.pos == PROPN) and (chunk.root.dep == pobj or chunk.root.dep == conj) :\n",
    "#         print(chunk.text)\n",
    "        OP_cnt[chunk.text] += 1\n",
    "\n",
    "for token in OP_doc:\n",
    "    if (token.dep_ == 'compound' and token.head.is_stop == False):\n",
    "#         print(token.lemma_, token.head.text)\n",
    "        txt = token.lemma_ + ' ' + token.head.text\n",
    "        if not not(nlp(txt).ents):\n",
    "            if nlp(txt).ents[0].label_ != 'GPE':\n",
    "                OP_cnt[txt] += 1\n",
    "        \n",
    "OP_cnt.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the city', 9),\n",
       " ('collaboration', 7),\n",
       " ('climate change', 7),\n",
       " ('Pratt Institute', 7),\n",
       " ('development', 6),\n",
       " ('budget schedule', 5),\n",
       " ('space', 5),\n",
       " ('order', 5),\n",
       " ('spring', 5),\n",
       " ('barbarians', 5),\n",
       " ('work includes', 4),\n",
       " ('assistant including', 4),\n",
       " ('prototyping', 4),\n",
       " ('grants', 4),\n",
       " ('RAMP', 4),\n",
       " ('summer', 4),\n",
       " ('personnel expenses', 4),\n",
       " ('research assistants', 4),\n",
       " ('students', 4),\n",
       " ('Knowledge Bank', 4),\n",
       " ('Milan Triennale', 4),\n",
       " ('Science Math', 3),\n",
       " ('stakeholder communities', 3),\n",
       " ('construction', 3),\n",
       " ('industry partners', 3),\n",
       " ('design studios', 3),\n",
       " ('a series', 3),\n",
       " ('architectural history', 3),\n",
       " ('power', 3),\n",
       " ('community', 3),\n",
       " ('the project', 3),\n",
       " ('the production', 3),\n",
       " ('drawings', 3),\n",
       " ('the public', 3),\n",
       " ('materials', 3),\n",
       " ('people', 3),\n",
       " ('symposium', 3),\n",
       " ('the field', 3),\n",
       " ('Graham Foundation', 3),\n",
       " ('50,000 100,000', 3),\n",
       " ('Change Center', 3),\n",
       " ('Yin Yu', 3),\n",
       " ('Amazon Cities', 3),\n",
       " ('horizontal vertical', 2),\n",
       " ('contributor coordinators', 2),\n",
       " ('proposal scales', 2),\n",
       " ('agency communities', 2),\n",
       " ('community agencies', 2),\n",
       " ('project adaptation', 2),\n",
       " ('practice projects', 2)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FR_cnt = Counter()\n",
    "for token in FR_doc:\n",
    "    if ((token.pos == NOUN or token.pos == ADJ or token.pos == PROPN) and (token.dep == pobj or token.dep == conj)):\n",
    "#         print(token.lemma_, token.head.text)\n",
    "        if token.head.is_stop == False:\n",
    "            txt = token.lemma_ + ' ' + token.head.text\n",
    "            FR_cnt[txt] += 1\n",
    "\n",
    "for chunk in FR_doc.noun_chunks:\n",
    "    if chunk.root.is_stop == False and (chunk.root.pos == NOUN or chunk.root.pos == ADJ or token.pos == PROPN) and (chunk.root.dep == pobj or chunk.root.dep == conj) :\n",
    "#         print(chunk.text)\n",
    "        FR_cnt[chunk.text] += 1\n",
    "\n",
    "for token in FR_doc:\n",
    "    if (token.dep_ == 'compound' and token.head.is_stop == False):\n",
    "#         print(token.lemma_, token.head.text)\n",
    "        txt = token.lemma_ + ' ' + token.head.text\n",
    "        if not not(nlp(txt).ents):\n",
    "            if nlp(txt).ents[0].label_ != 'GPE':\n",
    "                FR_cnt[txt] += 1\n",
    "        \n",
    "FR_cnt.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.DataFrame(RF_cnt.most_common(100), columns=['word','count'])\n",
    "df_ro = pd.DataFrame(RO_cnt.most_common(100), columns=['word','count'])\n",
    "df_kw = pd.DataFrame(KW_cnt.most_common(100), columns=['word','count'])\n",
    "df_or = pd.DataFrame(OP_cnt.most_common(100), columns=['word','count'])\n",
    "df_fr = pd.DataFrame(FR_cnt.most_common(100), columns=['word','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf.to_csv('./bow_researchFocus.csv', index=False)\n",
    "df_ro.to_csv('./bow_researchObjective.csv', index=False)\n",
    "df_kw.to_csv('./bow_keywords.csv', index=False)\n",
    "df_or.to_csv('./bow_or.csv', index=False)\n",
    "df_fr.to_csv('./bow_fr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
